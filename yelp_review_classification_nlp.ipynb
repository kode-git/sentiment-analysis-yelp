{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d35b8db",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on Yelp Open Dataset for Review Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cfcc62",
   "metadata": {},
   "source": [
    "Il notebook seguente andrà ad illustrare l'intero processo per l'implementazione di un modello di Sentiment Analysis in grado di classificare le reviews in positive o negative tramite l'uso di modelli di Deep Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77beb0bf",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9816f0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerie di default\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# librerie per il data analysis\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "%matplotlib inline\n",
    "\n",
    "# librerie per il text manipulation\n",
    "import gensim\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import nltk as nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from datetime import datetime\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# librerie per il data modelling\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787e548f",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0e9e55",
   "metadata": {},
   "source": [
    "Date le grandezze eccessive del dataset di input, si è deciso di caricare i dati al suo interno tramite la divisione in blocchi di grandezza pari a chunksize. Inoltre, tramite la documentazione fornita da Yelp, siamo stati in grado di tener conto del numero di byte da caricare grazie alla nota tipizzazione delle informazioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de54f167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definiamo i tipi degli attributi JSON per l'attributo dtype di read_json\n",
    "rtypes = {  \"review_id\": str,\n",
    "            \"user_id\":str,\n",
    "            \"business_id\":str,\n",
    "            \"stars\": np.float16, \n",
    "            \"useful\": np.int32, \n",
    "            \"funny\": np.int32,\n",
    "            \"cool\": np.int32,\n",
    "            \"text\" : str,\n",
    "           }\n",
    "\n",
    "# file path del dataset json\n",
    "path = './data/yelp_academic_dataset_review.json'\n",
    "\n",
    "# grandezza dei chunk\n",
    "chunkSize = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe4db53",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# creazione del JsonReader\n",
    "review = pd.read_json(path, lines=True,\n",
    "                      orient=\"records\",\n",
    "                      dtype=rtypes,\n",
    "                      chunksize=chunkSize)\n",
    "chunkList = []\n",
    "\n",
    "# utilizzo della segmentazione in chunk per creare dal JsonReader il dataframe\n",
    "for chunkReview in review:\n",
    "    # rimozione degli attributi id\n",
    "    chunkReview = chunkReview.drop(['review_id', 'user_id','business_id'], axis=1)\n",
    "    chunkList.append(chunkReview)\n",
    "    \n",
    "# concatenazione degli elementi nella chunkList per righe\n",
    "df = pd.concat(chunkList, ignore_index=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1102210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizzazione degli elementi in testa\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6835a436",
   "metadata": {},
   "source": [
    "## 2. Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca906c7e",
   "metadata": {},
   "source": [
    "Durante la fase di Data Analysis, abbiamo concentrato il nostro interesse interesse sul bilanciamento delle valutazioni relative alla colonna stars, possibili correlazioni tra le colonne numeriche secondarie (cool, funny, useful) e analisi sulle frequenze di parole e lunghezze dei testi per la colonna texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791a1d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# informazioni sulle colonne del dataframe e su quante entries o righe si hanno\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905d3170",
   "metadata": {},
   "source": [
    "### 2.1 Stars Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb555473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definire la grandezza della figura\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "# contare i vari valori di stars e visualizzarli su un diagramma a torta\n",
    "df['stars'].value_counts().plot.pie(startangle=60)\n",
    "\n",
    "# definire il titolo del plot\n",
    "plt.title('Distribuzione dei valori per l\\'attributo stars')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c08912e",
   "metadata": {},
   "source": [
    "Le quantità di recensioni, classificate in base al numero di stelle assegnate, è sbilanciata. Si ha un maggior numero per le recensioni con 5 e 4 stelle rispetto a quelle con 1, 2 o 3 stelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dd9c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribuzione dei valori in reviews positive e negative\n",
    "binstars = pd.DataFrame()\n",
    "binstars['stars'] = [0 if star <= 3.0 else 1 for star in df['stars']]\n",
    "# definire la grandezza della figura\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "\n",
    "# contare i vari valori di stars e visualizzarli su un diagramma a torta\n",
    "binstars['stars'].value_counts().plot.pie(startangle=60)\n",
    "\n",
    "# definire il titolo del plot\n",
    "plt.title('Distribuzione dei valori positivi e negativi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7315455f",
   "metadata": {},
   "source": [
    "### 2.2 Cool, Fun and Useful Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d714e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggiunta di una feature per l'analisi della lunghezza dei testi\n",
    "df['textLength']  = df['text'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63264560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definire le correlazioni\n",
    "corr = df.corr()\n",
    "\n",
    "# generazione dell'heatmap\n",
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008f57a4",
   "metadata": {},
   "source": [
    "Non sono presenti particolari correlazioni forti tra i funny, useful e cool con i valori dati a stars o text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084367cf",
   "metadata": {},
   "source": [
    "### 2.3 Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab1bd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# definisce un sottoinsieme delle righe del dataset\n",
    "subset = df[:100000]\n",
    "# concatenazione dei testi di ogni riga in una singola stringa\n",
    "inputText = ' '.join(subset['text']).lower()\n",
    "\n",
    "# creazione di un wordcloud andando ad ignorare le stopwords\n",
    "wordCloud = WordCloud(background_color='white', stopwords=gensim.parsing.preprocessing.STOPWORDS).generate(inputText)\n",
    "# setting della visualizzazione utilizzando una interpolazione bilineare\n",
    "plt.imshow(wordCloud, interpolation='bilinear')\n",
    "\n",
    "# rimozione degli assi\n",
    "plt.axis('off')\n",
    "# visualizzazione del wordcloud rappresentante le parole più usate nel testo di una recensione\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199ba73b",
   "metadata": {},
   "source": [
    "Poichè la maggior parte delle recensioni fanno riferimento ad attività che forniscono servizi (ristorazione o di altro genere), l'utilizzo di parole che possano descrivere il luogo o i vari aspetti dell'attività sono quelle riscontrate con più frequenza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceabfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcolo della frequenza dei termini più utilizzati\n",
    "wordTokens = word_tokenize(inputText)\n",
    "tokens = list()\n",
    "for word in wordTokens:\n",
    "    if word.isalpha() and word not in gensim.parsing.preprocessing.STOPWORDS:\n",
    "        tokens.append(word)\n",
    "tokenDist = FreqDist(tokens)\n",
    "# per questioni di visualizzazione, andiamo a prendere solamente i primi 20 termini utilizzati\n",
    "dist = pd.DataFrame(tokenDist.most_common(20),columns=['term', 'freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b4f358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rappresentazione grafica dei risultati\n",
    "fig = plt.figure(figsize=(14,8))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "x = dist['term']\n",
    "y = dist['freq']\n",
    "ax.bar(x,y)\n",
    "plt.title('Frequenza dei termini più utilizzati')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edef1df",
   "metadata": {},
   "source": [
    "Tramite il grafico delle frequenze, possiamo notare come la maggior parte delle recensioni sono di natura culinaria, ossia una descrizione del cibo che si è ordinato. Da osservare che, dato lo sbilanciamento delle valutazioni a favore delle recensioni con valutazioni maggiore, parole usate per giudizi positivi risultano con più frequenza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb126a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51cee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differenziazione della lunghezza dei testi in relazione alla valutazione data a stars\n",
    "graph = sns.FacetGrid(data=df,col='stars')\n",
    "graph.map(plt.hist,'textLength',bins=50,color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc785fb3",
   "metadata": {},
   "source": [
    "## 3. Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2df9d4e",
   "metadata": {},
   "source": [
    "La procedura di data pre-processing sarà utilizzata per la divisione delle valutazioni secondo una classificazione binaria (stars <= 3 per review negativa, positiva altrimenti). Durante tale fase, ci siamo concentrati principalmente sulla manipolazione del testo, nello specifico abbiamo ridotto la diversificazione delle parole andando a rimuovere segni di punteggiatura, stopwords e forme alternative. Infine, abbiamo utilizzato un tokenizer in grado di poter effettuare una conversione in valori numerici (stemmizzazione) dato che, trattandosi di deep learning, il calcolo relativo alle funzioni di attivazione e del processing interno di una rete si basa esclusivamente su valori di natura numerica. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b587a0",
   "metadata": {},
   "source": [
    "### 3.1 Rimozione colonne inutilizzate e valori nulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971f53e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cancellazione delle caratteristiche cool, funny, useful e textLength poichè non hanno correlazioni con stars.\n",
    "df = df.drop(['cool', 'funny', 'useful', 'textLength'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f634de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a24dbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rimozione di possibili testi vuoti\n",
    "df['text'].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dd3d5f",
   "metadata": {},
   "source": [
    "### 3.2 Riduzione dei testi in lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0549018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ridurre la forma delle parole in minuscolo\n",
    "df['text'] = [review_text.lower() for review_text in df['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593189b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b54a60",
   "metadata": {},
   "source": [
    "### 3.3 Polarizzazione dei labels (stars) e bilanciamento del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a393a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polarizzazione delle valutazioni a stars in due categorie: 1 = positiva, 0 = negativa\n",
    "\n",
    "# isoliamo la colonna di testo del dataframe in texts\n",
    "texts =  df['text']\n",
    "\n",
    "# andiamo ad impostare negative tutte le recensioni con 3 o meno stelle e positive quelle con 4 e 5 stelle.\n",
    "stars = [0 if star <= 3.0 else 1 for star in df['stars']]\n",
    "\n",
    "balancedTexts = [] # rappresenta la collezione di testi presi in considerazione dal dataframe di input\n",
    "balancedLabels = [] # rappresenta il nuovo valore polarizzato assegnato all'entry (0,1)\n",
    "\n",
    "# andiamo a bilanciare il dataset andando a dividere recensioni positive e negative con limite di 1.000.000 per categoria\n",
    "limit = 100000  \n",
    "\n",
    "# posizione 0 per conteggio di recensioni negative, posizione 1 per quelle positive\n",
    "negPosCounts = [0, 0] \n",
    "\n",
    "for i in range(0,len(texts)):\n",
    "    polarity = stars[i]\n",
    "    if negPosCounts[polarity] < limit: # se non si è raggiunto il limite per la categoria di polarizzazione\n",
    "        balancedTexts.append(texts[i])\n",
    "        balancedLabels.append(stars[i])\n",
    "        negPosCounts[polarity] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd735018",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = pd.DataFrame()\n",
    "df_balanced['text'] = balancedTexts\n",
    "df_balanced['labels'] = balancedLabels\n",
    "df_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11e8cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifica del conteggio\n",
    "counter = Counter(df_balanced['labels'])\n",
    "print(f'Ci sono {counter[1]} recensioni positive e {counter[0]} recensioni negative')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1390066f",
   "metadata": {},
   "source": [
    "### 3.3 Lemmatizzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13106c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# creazione del lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# funzione per l'aggiunta del tag semantico che evidenzia il tipo di parola da dover selezionare\n",
    "def word_tagger(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:         \n",
    "        return None\n",
    "\n",
    "\n",
    "# elaborazione sui testi del dataset\n",
    "texts = df_balanced['text']\n",
    "df_texts = []\n",
    "for text in texts:\n",
    "    # tokenizzazione del text per l'aggiunta dei tag\n",
    "    word_tagged = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "    # mapping parole:tag del testo analizzato\n",
    "    map_word_tag = list(map(lambda x: (x[0], word_tagger(x[1])), word_tagged))\n",
    "    # costruzione del testo lemmatizzato\n",
    "    lemmatized_text = []\n",
    "    for word, tag in map_word_tag:\n",
    "        if tag is None:\n",
    "            # elemento non tokenizzabile\n",
    "            lemmatized_text.append(word)\n",
    "        else:\n",
    "            # lemmmatizzazione della parola in relazione al \n",
    "            # tipo di elemento\n",
    "            lemmatized_text.append(lemmatizer.lemmatize(word, tag))\n",
    "    # aggiunta della parola post-lemmatizzazione al testo selezionato\n",
    "    lemmatized_text = \" \".join(lemmatized_text)\n",
    "    # aggiunta del testo nella collezione dei testi lemmatizzati\n",
    "    df_texts.append(lemmatized_text)\n",
    "\n",
    "print(texts[0] + \"\\n\\n\")\n",
    "print(df_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19e9428",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced['text'] = df_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c9a2b4",
   "metadata": {},
   "source": [
    "### 3.4 Rimozione delle stop words e di caratteri non alfanumerici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c06e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop words da rimuovere\n",
    "print(gensim.parsing.preprocessing.STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d93279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rimozione delle stop words\n",
    "df_texts = []\n",
    "for text in df_balanced['text']:\n",
    "    df_texts.append(remove_stopwords(text))\n",
    "\n",
    "df_balanced['text'] = df_texts\n",
    "\n",
    "# Rimozione dei caratteri non alfanumerici\n",
    "df_texts = []\n",
    "for text in df_balanced['text']:\n",
    "    df_texts.append(''.join(ch for ch in text if ch.isalnum() or ch == ' '))\n",
    "\n",
    "df_balanced['text'] = df_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad80eab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_balanced['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89c9c97",
   "metadata": {},
   "source": [
    "### 3.5 Text Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381069a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# tokenizzazione del testo andando a dividere le stringhe in una lista di lemmi\n",
    "df_balanced['text'] = [nltk.word_tokenize(text) for text in df_balanced['text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff653e0",
   "metadata": {},
   "source": [
    "### 3.6 Preparazione Dati Vettoriali per la Fase di Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb23c27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definire il numero di parole da passare all'oggetto Tokenizer\n",
    "# bisogna analizzare la quantità di parole che si ha nel dataframe selezionato\n",
    "map_terms = dict()\n",
    "for text in df_balanced['text']:\n",
    "    for word in text:\n",
    "        if word not in map_terms:\n",
    "            map_terms[word] = 1\n",
    "\n",
    "print(f'There are {len(map_terms)} different words') # number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6637a1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# definizione di un tokenizer delle prime 10.000 parole più utilizzate\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(df_balanced['text'])\n",
    "# trasformazione della sequenza di lemmi in sequenze di interi in modo da valutare più velocemente le parole\n",
    "sequences = tokenizer.texts_to_sequences(df_balanced['text'])\n",
    "# Sequenze di massimo 200 unità. Se vi sono testi con sequenze più lunghe esse vengono troncate, altrimenti si avrà \n",
    "# un riempimenti di 0 per testi undersized.\n",
    "text_sequence = pad_sequences(sequences, maxlen=200)\n",
    "labels = np.array(df_balanced['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66db667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check parziale degli indici delle parole \n",
    "word_index = tokenizer.word_index\n",
    "# prendiamo le prime 50 parole indicizzate\n",
    "check = {key: value for key, value in word_index.items() if value <= 50}\n",
    "print(check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d896f003",
   "metadata": {},
   "source": [
    "Il vettore dei valori numerici ha un dominio pari a 20.000 parole differenti tra le 132.062 parole totali. Si andrà, quindi, a selezionare 1/6 delle parole presenti nelle reviews che, però, ha una rilevanza maggiore rispetto ai 5/6 restanti poichè hanno occorrenze maggiori. Inoltre, la sequenza ordinata creata andrà a seguire l'ordine di occorenza dei termini all'interno dei testi di 300 parole (grandezza massima)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0285bbcc",
   "metadata": {},
   "source": [
    "## 4. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7de35bd",
   "metadata": {},
   "source": [
    "In questa fase è possibile trovare modelli alternativi utilizzati oggigiorno nel campo NLP. Nello specifico, si propone una triplice alternativa che vede l'utilizzo di un modello basato su LSTM, un modello di convulational neural network che va a supporto di LSTM e, infine, un modello di LSTM bidirezionale. Possiamo affermare che tutti i modelli hanno raggiunto un livello di precisione accettabile; ciò non toglie che vi possano essere vari miglioramenti che possano incrementarne le prestazioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbcc790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking sulle compile flags di tensorflow\n",
    "print(tf.sysconfig.get_compile_flags())\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c41c099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe per calcolare F1-Score delle epoche durante la fase di training e validation dei modelli\n",
    "class F1History(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, train, validation=None):\n",
    "        super(F1History, self).__init__()\n",
    "        self.validation = validation\n",
    "        self.train = train\n",
    "\n",
    "    # stampa dei valori di F1-Score alla fine di ogni epoch\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "\n",
    "        logs['F1_score_train'] = float('-inf')\n",
    "        X_train, y_train = self.train[0], self.train[1]\n",
    "        y_pred = (self.model.predict(X_train).ravel()>0.5)+0\n",
    "        score = f1_score(y_train, y_pred)       \n",
    "\n",
    "        if (self.validation):\n",
    "            logs['F1_score_val'] = float('-inf')\n",
    "            X_valid, y_valid = self.validation[0], self.validation[1]\n",
    "            y_val_pred = (self.model.predict(X_valid).ravel()>0.5)+0\n",
    "            val_score = f1_score(y_valid, y_val_pred)\n",
    "            logs['F1_score_train'] = np.round(score, 5)\n",
    "            logs['F1_score_val'] = np.round(val_score, 5)\n",
    "        else:\n",
    "            logs['F1_score_train'] = np.round(score, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4176dd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test splitting\n",
    "x_train, x_test, y_train, y_test = train_test_split(text_sequence , labels ,random_state=520, test_size=0.33, shuffle=True)\n",
    "\n",
    "# train and validation splitting\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train, y_train, test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd17eb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_train))\n",
    "print(len(x_val))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1981654f",
   "metadata": {},
   "source": [
    "### 4.1 Modello basato su LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2650a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creazione di un modello sequenziale vuoto in cui aggiungere i vari layers\n",
    "model_lstm = keras.Sequential()\n",
    "\n",
    "# aggiunta dei layers\n",
    "model_lstm.add(layers.Embedding(10000, 128, \n",
    "                                input_length=200))\n",
    "model_lstm.add(layers.LSTM(128, \n",
    "                           dropout=0.2, \n",
    "                           recurrent_dropout=0.2));\n",
    "model_lstm.add(layers.Dense(1, activation='sigmoid'));\n",
    "\n",
    "model_lstm.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb406e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lstm = model_lstm.fit(x_train, y_train, epochs=3, callbacks=[F1History(train=(x_train,y_train),validation=(x_val,y_val))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2791e52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024fdafd",
   "metadata": {},
   "source": [
    "modelLSTM.evaluate(xTest, yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495a67ee",
   "metadata": {},
   "source": [
    "### 4.2 Modello basato su CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1891b39d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_cnn = keras.Sequential()\n",
    "model_cnn.add(layers.Embedding(10000, 128, input_length=200)) #layer iniziali \n",
    "model_cnn.add(layers.Dropout(0.25)) # layer di dropout esterno in seguito ad Embedding\n",
    "model_cnn.add(layers.Conv1D(128,\n",
    "                        4,\n",
    "                        activation='relu'))\n",
    "model_cnn.add(layers.MaxPooling1D(pool_size=4))\n",
    "model_cnn.add(layers.Flatten())\n",
    "model_cnn.add(layers.Dense(128, activation='relu'))\n",
    "model_cnn.add(layers.Dropout(0.25))\n",
    "model_cnn.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model_cnn.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c044609",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_cnn = model_cnn.fit(x_train, y_train, epochs=3, callbacks=[F1History(train=(x_train,y_train),validation=(x_val,y_val))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d38370",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3892c2b6",
   "metadata": {},
   "source": [
    "### 4.1.1 Modello basato CNN + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02543de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creazione di un modello sequenziale vuoto in cui aggiungere i vari layers\n",
    "model_lstm = keras.Sequential()\n",
    "\n",
    "# aggiunta dei layers\n",
    "model_lstm.add(layers.Embedding(10000, 128, input_length=200))\n",
    "model_lstm.add(layers.Dropout(0.25)) # aggiunta di un layer di dropout per la regolarizzazione versoo i convulational layers\n",
    "model_lstm.add(layers.Conv1D(128, \n",
    "                             4, \n",
    "                             activation='relu'))\n",
    "model_lstm.add(layers.MaxPooling1D(pool_size=4))\n",
    "model_lstm.add(layers.LSTM(128));\n",
    "model_lstm.add(layers.Dropout(0.25)) # aggiunta di un layer di dropout che prende l'output dei layer LSTM in input\n",
    "model_lstm.add(layers.Dense(1, activation='sigmoid')); \n",
    "\n",
    "model_lstm.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32db6b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lstm = model_lstm.fit(x_train, y_train, epochs=3, callbacks=[F1History(train=(x_train,y_train),validation=(x_val,y_val))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f0803f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d53c8e7",
   "metadata": {},
   "source": [
    "### 4.3 Modello basato su LSTM bidirezionale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7253c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bid = keras.Sequential()\n",
    "model_bid.add(layers.Embedding(10000, 128, input_length=200))\n",
    "model_bid.add(layers.Dropout(0.25))\n",
    "model_bid.add(layers.Conv1D(128,\n",
    "                        4,\n",
    "                        activation='relu'))\n",
    "model_bid.add(layers.MaxPooling1D(pool_size=4))\n",
    "model_bid.add(layers.Bidirectional(layers.LSTM(128)))\n",
    "model_bid.add(layers.Dropout(0.25))\n",
    "model_bid.add(layers.Dense(1, activation='sigmoid'))\n",
    "model_bid.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model_bid.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ea821a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_bid = model_bid.fit(x_train, y_train, epochs=3, callbacks=[F1History(train=(x_train,y_train),validation=(x_val,y_val))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272f09fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bid.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30d24b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.metrics import TruePositives, TrueNegatives, FalseNegatives, FalsePositives\n",
    "\n",
    "model_bid_lstm = keras.Sequential([layers.Embedding(10000, 128, input_length=200),\n",
    "                               layers.Dropout(0.25),\n",
    "                               layers.Conv1D(128, 4, activation='relu'),\n",
    "                               layers.MaxPooling1D(pool_size=4),\n",
    "                               layers.Bidirectional(layers.LSTM(64, return_sequences = True)),\n",
    "                               layers.LSTM(32, recurrent_dropout=0.4),\n",
    "                               layers.Dropout(0.25),\n",
    "                               layers.Dense(1, activation='sigmoid')])\n",
    "model_bid_lstm.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_bid_lstm.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86106df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_bid_lstm = model_bid_lstm.fit(x_train, y_train, epochs=3, callbacks=[F1History(train=(x_train,y_train),validation=(x_val,y_val))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130a83ec",
   "metadata": {},
   "source": [
    "## 5. Save Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fbde99",
   "metadata": {},
   "source": [
    "Data l'eccessiva tempo speso per l'addestramento delle reti neurali proposte, abbiamo deciso di salvare tramite la libreria pickle le componenti e i modelli addestrati in modo da poterli rendere disponibili per l'analisi delle prestazioni e l'utilizzo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010bbab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# salviamo il tokenizer e i modelli su file\n",
    "with open(\"dump/keras_tokenizer.pickle\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "    \n",
    "model_lstm.save(\"dump/model/yelp_model_lstm.hdf5\")\n",
    "model_cnn.save(\"dump/model/yelp_model_cnn.hdf5\")\n",
    "model_bid.save(\"dump/model/yelp_bidirectional_lstm.hdf5\")\n",
    "model_bid_lstm.save(\"dump/model/yelp_combination_bid_lstm.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a0eb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "\n",
    "# carichiamo il tokenizer e il modello da file\n",
    "with open(\"dump/keras_tokenizer.pickle\", \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "# TODO: load other models\n",
    "model_lstm = load_model(\"dump/model/yelp_model_lstm.hdf5\")\n",
    "model_cnn = load_model(\"dump/model/yelp_model_cnn.hdf5\")\n",
    "model_bid = load_model(\"dump/model/yelp_bidirectional_lstm.hdf5\")\n",
    "model_bid_lstm = load_model(\"dump/model/yelp_combination_bid_lstm.hdf5\")\n",
    "\n",
    "# definiamo gli esempi su cui testare il modello\n",
    "examples_reviews = [\"slow orders but good food\", \"Delicious foods! Awesome!\", \"Bad food, bad people... horrible!\"]\n",
    "\n",
    "# usiamo il tokenizer per creare sequenze di interi da dare al modello\n",
    "sequences = tokenizer.texts_to_sequences(examples_reviews)\n",
    "data_examples = pad_sequences(sequences, maxlen=200)\n",
    "\n",
    "# effettuare le predizioni e stampare i risultati\n",
    "predictions_lstm = model_lstm.predict(data_examples)\n",
    "predictions_cnn = model_cnn.predict(data_examples)\n",
    "predictions_bid = model_bid.predict(data_examples)\n",
    "predictions_bid_lstm = model_bid_lstm.predict(data_examples)\n",
    "\n",
    "print(f\"Risultati modello LSTM:\\n {predictions_lstm}\\n\\n\"+\n",
    "    f\"Risultati modello CNN:\\n {predictions_cnn}\\n\\n\" + \n",
    "      f\"Risultati modello biLSTM:\\n {predictions_bid}\\n\\n\" +\n",
    "     f\"Risultati modello combinato biLSTM + LSTM:\\n {predictions_bid_lstm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0881c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grafico di paragone per i valori della training accuracy tra i modelli proposti\n",
    "plt.plot(results_bid.history['accuracy'])\n",
    "plt.plot(results_cnn.history['accuracy'])\n",
    "plt.plot(results_lstm.history['accuracy'])\n",
    "plt.plot(results_bid_lstm.history['accuracy'])\n",
    "plt.title('Analisi training accuracy dei modelli')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['biLSTM', 'CNN', 'LSTM', 'biLSTM+LSTM'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# grafico di paragone per i valori della loss function tra i modelli proposti\n",
    "plt.plot(results_bid.history['loss'])\n",
    "plt.plot(results_cnn.history['loss'])\n",
    "plt.plot(results_lstm.history['loss'])\n",
    "plt.plot(results_bid_lstm.history['loss'])\n",
    "plt.title('Analisi valori loss dei modelli')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['biLSTM', 'CNN', 'LSTM', 'biLSTM+LSTM'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "# grafico di paragone per i valori dell'accuracy in validazione\n",
    "plt.plot(results_bid.history['val_accuracy'])\n",
    "plt.plot(results_cnn.history['val_accuracy'])\n",
    "plt.plot(results_lstm.history['val_accuracy'])\n",
    "plt.plot(results_bid_lstm.history['val_accuracy'])\n",
    "plt.title('Analisi validation accuracy dei modelli')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['biLSTM', 'CNN', 'LSTM', 'biLSTM+LSTM'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36081a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_cnn.history\n",
    "\n",
    "# grafico di paragone per i valori del F1-Score in training\n",
    "plt.plot(results_bid.history['F1_score_train'])\n",
    "plt.plot(results_cnn.history['F1_score_train'])\n",
    "plt.plot(results_lstm.history['F1_score_train'])\n",
    "plt.plot(results_bid_lstm.history['F1_score_train'])\n",
    "plt.title('Analisi F1 Score sul training set dei modelli')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['biLSTM', 'CNN', 'LSTM', 'biLSTM+LSTM'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "# grafico di paragone per i valori del F1-Score in validation\n",
    "plt.plot(results_bid.history['F1_score_val'])\n",
    "plt.plot(results_cnn.history['F1_score_val'])\n",
    "plt.plot(results_lstm.history['F1_score_val'])\n",
    "plt.plot(results_bid_lstm.history['F1_score_val'])\n",
    "plt.title('Analisi F1 Score sul validation set nei modelli')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['biLSTM', 'CNN', 'LSTM', 'biLSTM+LSTM'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd43af78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
