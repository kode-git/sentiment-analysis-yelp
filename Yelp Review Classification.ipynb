{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d35b8db",
   "metadata": {},
   "source": [
    "# NLP on Yelp Open Dataset for Review Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cfcc62",
   "metadata": {},
   "source": [
    "Questo notebook ha il compito di effettuare tramite NLP una classificazione delle reviews in positive e negative andando ad analizzare testi tokenizzati all'interno del dataset fornito da Open Yelp Dataset. Ci soffermeremo solamente sulla tabella dedicata alla review poichè si giudicano sufficiente, per raggiungere un livello di precisione accettabile, le informazioni contenute all'interno delle colonne della tabella review fornita in input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77beb0bf",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9816f0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerie di default\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# librerie per il data analysis\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "%matplotlib inline\n",
    "\n",
    "# librerie per il text manipulation\n",
    "import nltk as nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "import gensim\n",
    "from gensim.parsing.preprocessing import remove_stopwords, STOPWORDS, strip_non_alphanum\n",
    "from nltk.corpus import wordnet as wn\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from datetime import datetime\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# librerie per il data modelling\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787e548f",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0e9e55",
   "metadata": {},
   "source": [
    "La fase di data loading non fa altro che caricare all'interno di un pandas dataframe le informazioni contenute nel dataset JSON in formato tabellare per poi utilizzarlo nella fase di data analysis per visualizzare le correlazioni e i valori al suo interno tramite visualizzazione grafica in modo da rendersi conto di che tipo e in che quantità sono distribuiti i dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de54f167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definiamo i tipi degli attributi JSON per l'attributo dtype di read_json\n",
    "rtypes = {  \"review_id\": str,\n",
    "            \"user_id\":str,\n",
    "            \"business_id\":str,\n",
    "            \"stars\": np.float16, \n",
    "            \"useful\": np.int32, \n",
    "            \"funny\": np.int32,\n",
    "            \"cool\": np.int32,\n",
    "            \"text\" : str,\n",
    "           }\n",
    "\n",
    "# file path del dataset json\n",
    "path = './data/yelp_academic_dataset_review.json'\n",
    "\n",
    "# grandezza dei chunk\n",
    "chunkSize = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe4db53",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# creazione del JsonReader\n",
    "review = pd.read_json(path, lines=True,\n",
    "                      dtype=rtypes,\n",
    "                      chunksize=chunkSize)\n",
    "chunkList = []\n",
    "\n",
    "# utilizzo della segmentazione in chunk per creare dal JsonReader il dataframe\n",
    "for chunkReview in review:\n",
    "    # rimozione degli attributi id\n",
    "    chunkReview = chunkReview.drop(['review_id', 'user_id','business_id'], axis=1)\n",
    "    chunkList.append(chunkReview)\n",
    "    \n",
    "# concatenazione degli elementi nella chunkList per righe\n",
    "df = pd.concat(chunkList, ignore_index=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1102210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizzazione degli elementi in testa\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6835a436",
   "metadata": {},
   "source": [
    "## 2. Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca906c7e",
   "metadata": {},
   "source": [
    "Durante la fase di data analysis andremo ad ispezionare il dataframe caricato andando a visualizzare graficamente come sono distribuiti i valori associati ad ogni attributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791a1d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# informazioni sulle colonne del dataframe e su quante entries o righe si hanno\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905d3170",
   "metadata": {},
   "source": [
    "### 2.1 Stars Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb555473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definire la grandezza della figura\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "# contare i vari valori di stars e visualizzarli su un diagramma a torta\n",
    "df['stars'].value_counts().plot.pie(startangle=60)\n",
    "\n",
    "# definire il titolo del plot\n",
    "plt.title('Distribuzione dei valori per l\\'attributo stars')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c08912e",
   "metadata": {},
   "source": [
    "Le quantità di recensioni, classificate in base al numero di stelle assegnate, è sbilanciata. Si ha un maggior numero per le recensioni con 5 e 4 stelle rispetto a quelle con 1, 2 o 3 stelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dd9c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribuzione dei valori in reviews positive e negative\n",
    "binstars = pd.DataFrame()\n",
    "binstars['stars'] = [0 if star <= 3.0 else 1 for star in df['stars']]\n",
    "# definire la grandezza della figura\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "\n",
    "# contare i vari valori di stars e visualizzarli su un diagramma a torta\n",
    "binstars['stars'].value_counts().plot.pie(startangle=60)\n",
    "\n",
    "# definire il titolo del plot\n",
    "plt.title('Distribuzione dei valori positivi e negativi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7315455f",
   "metadata": {},
   "source": [
    "### 2.2 Cool, Fun and Useful Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63264560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definire le correlazioni\n",
    "corr = df.corr()\n",
    "\n",
    "# generazione dell'heatmap\n",
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008f57a4",
   "metadata": {},
   "source": [
    "Non sono presenti particolari correlazioni forti tra i funny, useful e cool con i valori dati a stars."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084367cf",
   "metadata": {},
   "source": [
    "### 2.3 Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab1bd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# definisce un sottoinsieme delle righe del dataset\n",
    "subset = df[:100000]\n",
    "# concatenazione dei testi di ogni riga in una singola stringa\n",
    "inputText = ' '.join(subset['text']).lower()\n",
    "\n",
    "# creazione di un wordcloud andando ad ignorare le stopwords\n",
    "wordCloud = WordCloud(background_color='white', stopwords=STOPWORDS).generate(inputText)\n",
    "# setting della visualizzazione utilizzando una interpolazione bilineare\n",
    "plt.imshow(wordCloud, interpolation='bilinear')\n",
    "\n",
    "# rimozione degli assi\n",
    "plt.axis('off')\n",
    "# visualizzazione del wordcloud rappresentante le parole più usate nel testo di una recensione\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceabfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcolo della frequenza dei termini più utilizzati\n",
    "wordTokens = word_tokenize(inputText)\n",
    "tokens = list()\n",
    "for word in wordTokens:\n",
    "    if word.isalpha() and word not in STOPWORDS:\n",
    "        tokens.append(word)\n",
    "tokenDist = FreqDist(tokens)\n",
    "# per questioni di visualizzazione, andiamo a prendere solamente i primi 20 termini utilizzati\n",
    "dist = pd.DataFrame(tokenDist.most_common(20),columns=['term', 'freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b4f358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rappresentazione grafica dei risultati\n",
    "fig = plt.figure(figsize=(14,8))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "x = dist['term']\n",
    "y = dist['freq']\n",
    "ax.bar(x,y)\n",
    "plt.title('Frequenza dei termini più utilizzati')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d714e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggiunta di una feature per l'analisi della lunghezza dei testi\n",
    "df['textLength']  = df['text'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb126a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51cee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differenziazione della lunghezza dei testi in relazione alla valutazione data a stars\n",
    "graph = sns.FacetGrid(data=df,col='stars')\n",
    "graph.map(plt.hist,'textLength',bins=50,color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc785fb3",
   "metadata": {},
   "source": [
    "## 3. Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7498a85",
   "metadata": {},
   "source": [
    "Durante la fase di pre-processing, andiamo a pulire e bilanciare il dataframe in modo da poterlo utilizzare per il data modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b587a0",
   "metadata": {},
   "source": [
    "### 3.1 Cancellazione Colonne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971f53e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cancellazione delle caratteristiche cool, funny, useful e textLength poichè non hanno correlazioni con stars.\n",
    "df = df.drop(['cool', 'funny', 'useful', 'textLength'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f634de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a24dbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rimozione di possibili testi vuoti\n",
    "df['text'].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0549018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ridurre la forma delle parole in minuscolo\n",
    "df['text'] = [review_text.lower() for review_text in df['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593189b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b54a60",
   "metadata": {},
   "source": [
    "### 3.2 Stars Polarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a393a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polarizzazione delle valutazioni a stars in due categorie: 1 = positiva, 0 = negativa\n",
    "\n",
    "# isoliamo la colonna di testo del dataframe in texts\n",
    "texts =  df['text']\n",
    "\n",
    "# andiamo ad impostare negative tutte le recensioni con 3 o meno stelle e positive quelle con 4 e 5 stelle.\n",
    "stars = [0 if star <= 3.0 else 1 for star in df['stars']]\n",
    "\n",
    "balancedTexts = [] # rappresenta la collezione di testi presi in considerazione dal dataframe di input\n",
    "balancedLabels = [] # rappresenta il nuovo valore polarizzato assegnato all'entry (0,1)\n",
    "\n",
    "# andiamo a bilanciare il dataset andando a dividere recensioni positive e negative con limite di 1.000.000 per categoria\n",
    "limit = 100000  \n",
    "\n",
    "# posizione 0 per conteggio di recensioni negative, posizione 1 per quelle positive\n",
    "negPosCounts = [0, 0] \n",
    "\n",
    "for i in range(0,len(texts)):\n",
    "    polarity = stars[i]\n",
    "    if negPosCounts[polarity] < limit: # se non si è raggiunto il limite per la categoria di polarizzazione\n",
    "        balancedTexts.append(texts[i])\n",
    "        balancedLabels.append(stars[i])\n",
    "        negPosCounts[polarity] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd735018",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = pd.DataFrame()\n",
    "df_balanced['text'] = balancedTexts\n",
    "df_balanced['labels'] = balancedLabels\n",
    "df_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11e8cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifica del conteggio\n",
    "counter = Counter(df_balanced['labels'])\n",
    "print(f'Ci sono {counter[1]} recensioni positive e {counter[0]} recensioni negative')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89c9c97",
   "metadata": {},
   "source": [
    "### 3.3 Text Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381069a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization\n",
    "df_balanced['text'] = [word_tokenize(text) for text in df_balanced['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f731dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop words\n",
    "stop_words = np.array(STOPWORDS)\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff653e0",
   "metadata": {},
   "source": [
    "### 3.4 Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6855e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# rimozione delle stop words\n",
    "df_balanced['text'] = [word for word in df_balanced['text'] if not word in stop_words]\n",
    "temp_texts = [] \n",
    "temp_words = []\n",
    "# rimozione delle parole non alfanumeriche\n",
    "for text in df_balanced['text']:\n",
    "    for word in text:\n",
    "        if word.isalnum():\n",
    "            temp_words.append(word)\n",
    "    temp_texts.append(temp_words)\n",
    "    temp_words = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70432cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced['text'] = temp_texts\n",
    "df_balanced['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbcc790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking sulle compile flags di tensorflow\n",
    "print(tf.sysconfig.get_compile_flags())\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6637a1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# definizione di un tokenizer di 5.000 parole prese dal dataframe\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(df_balanced['text'])\n",
    "# trasformazione del testo in sequenze di interi in modo da valutare più velocemente le parole\n",
    "sequences = tokenizer.texts_to_sequences(df_balanced['text'])\n",
    "# Sequenze di massimo 200 unità. Se vi sono testi con sequenze più lunghe esse vengono troncate, altrimenti si avrà \n",
    "# un riempimenti di 0 per testi undersized.\n",
    "text_sequence = pad_sequences(sequences, maxlen=200)\n",
    "labels = np.array(df_balanced['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4176dd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test splitting\n",
    "x_train, x_test, y_train, y_test = train_test_split(text_sequence , labels ,test_size=0.5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2650a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creazione di un modello sequenziale vuoto in cui aggiungere i vari layers\n",
    "model_lstm = keras.Sequential()\n",
    "\n",
    "# aggiunta dei layers\n",
    "model_lstm.add(layers.Embedding(25000, 128, input_length=250))\n",
    "model_lstm.add(layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2)) # dropout dentro il layer LSTM\n",
    "model_lstm.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_lstm.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb406e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lstm = model_lstm.fit(x_train, y_train, validation_split=0.33, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2791e52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024fdafd",
   "metadata": {},
   "source": [
    "modelLSTM.evaluate(xTest, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1891b39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm_v2 = keras.Sequential()\n",
    "model_lstm_v2.add(layers.Embedding(25000, 128, input_length=250))\n",
    "model_lstm_v2.add(layers.Dropout(0.5)) # layer di dropout esterno in seguito ad Embedding\n",
    "model_lstm_v2.add(layers.Conv1D(64, 5, activation='relu'))\n",
    "model_lstm_v2.add(layers.MaxPooling1D(pool_size=4))\n",
    "model_lstm_v2.add(layers.LSTM(128))\n",
    "model_lstm_v2.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model_lstm_v2.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model_lstm_v2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c044609",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_lstm_v2.fit(x_train, y_train, validation_split=0.33, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d38370",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm_v2.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7253c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bid = keras.Sequential()\n",
    "model_bid.add(layers.Embedding(25000, 128, input_length=250))\n",
    "model_bid.add(layers.Dropout(0.5))\n",
    "model_bid.add(layers.Conv1D(64, 5, activation='relu'))\n",
    "model_bid.add(layers.Bidirectional(layers.LSTM(128)))\n",
    "model_bid.add(layers.Dense(1, activation='sigmoid'))\n",
    "model_bid.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model_bid.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ea821a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bid.fit(x_train, y_train, validation_split=0.33, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272f09fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bid.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130a83ec",
   "metadata": {},
   "source": [
    "## 5. Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71432b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4.2 Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010bbab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# salviamo il tokenizer e i modelli su file\n",
    "with open(\"dump/keras_tokenizer.pickle\", \"wb\") as f:\n",
    "   pickle.dump(tokenizer, f)\n",
    "with open(\"dump/tokenizer/yelp_model_lstm.hdf5\",\"wb\") as lstm_file:\n",
    "    model_lstm.save(lstm_file)\n",
    "          \n",
    "with open(\"dump/model/yelp_model_lstm_v2.hdf5\", \"wb\") as lstm_v2_file:\n",
    "    model_lstm_v2.save(lstm_v2_file)\n",
    "    \n",
    "with open(\"dump/model/yelp_bidirectional.hdf5\", \"wb\") as bid_file:\n",
    "    model_bid.save(bid_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a0eb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "\n",
    "# carichiamo il tokenizer e il modello da file\n",
    "with open(\"keras_tokenizer.pickle\", \"rb\") as f:\n",
    "   tokenizer = pickle.load(f)\n",
    "\n",
    "# TODO: load other models\n",
    "model_lstm = load_model(\"dump/model/yelp_model_lstm.hdf5\")\n",
    "model_lstm_v2 = load_model(\"dump/model/yelp_model_lstm_v2.hdf5\")\n",
    "model_bid = load_model(\"dump/model/yelp_bidirectional.hdf5\")\n",
    "\n",
    "# definiamo gli esempi su cui testare il modello\n",
    "examples_reviews = [\"slow orders but good food\", \"Delicious foods! Awesome!\", \"Bad food, bad people... horrible!\"]\n",
    "\n",
    "# usiamo il tokenizer per creare sequenze di interi da dare al modello\n",
    "sequences = tokenizer.texts_to_sequences(examples_reviews)\n",
    "data_examples = pad_sequences(sequences, maxlen=250)\n",
    "\n",
    "# effettuare le predizioni e stampare i risultati\n",
    "predictions_lstm = model_lstm.predict(data_examples)\n",
    "predictions_lstm_v2 = model_lstm_v2.predict(data_examples)\n",
    "predictions_bid = model_bid.predict(data_examples)\n",
    "\n",
    "print(f\"Risultati model_lstm: {predictions_lstm}\\n\"+\n",
    "    f\"Risultati model_lstm_v2: {predictions_lstm_v2}\\n\" + \n",
    "      f\"Risultati model_bid: {predictions_bid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a50486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Data Analytics sui risultati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068150a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3aca55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e38efd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe437376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce3d4de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9736890a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9d64a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
