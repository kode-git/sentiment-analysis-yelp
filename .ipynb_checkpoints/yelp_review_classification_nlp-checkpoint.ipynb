{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d35b8db",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on Yelp Open Dataset for Review Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cfcc62",
   "metadata": {},
   "source": [
    "Sentiment Analysis represents one of the most popular types of Natural Language Processing together with Speech Recognition. What we intend to do within the project is to study various learning models to find an efficient ensemble that can define whether a Yelp review is positive or negative. The project will consist of studying an open-source dataset made available by Yelp for academic purposes, defining its properties, manipulating the data to prepare for training, generating models according to particular structures, saving them and analyzing the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77beb0bf",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258f8185",
   "metadata": {},
   "source": [
    "The libraries have been divided into categories, based on how they are used within the notebook. Functions based on classic ML libraries such as tensorflow and sklearn, for handling text manipulation such as nltk and gensim, and data analysis methods provided by seaborn, matplotlib and worldcloud have been used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9816f0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# data analysis\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "%matplotlib inline\n",
    "\n",
    "# text manipulation\n",
    "import gensim\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import nltk as nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# dataset manipulation\n",
    "from collections import Counter, defaultdict\n",
    "from datetime import datetime\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# data modelling\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "\n",
    "# save models\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787e548f",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0e9e55",
   "metadata": {},
   "source": [
    "One of the first obstacles in the project is the data loading. Dataset file size is at most 5GB, which means that loading the entire data file directly could have resulted in inappropriate use of memory. To solve this problem, we have divided the file into blocks or chunks of data with a predetermined size, in order to lighten the load of data in memory and facilitate the CPU working. In order to obtain a performing procedure, the process took into considering the types of the Json data features to be able to know before the amount of bytes to be analyzed and loaded. At the end of the procedure, the various blocks were unified into a dataframe, a data structure made available by the Python pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de54f167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define features types on the file to reduce the loading time\n",
    "\n",
    "rtypes = {  \"review_id\": str,\n",
    "            \"user_id\":str,\n",
    "            \"business_id\":str,\n",
    "            \"stars\": np.float16, \n",
    "            \"useful\": np.int32, \n",
    "            \"funny\": np.int32,\n",
    "            \"cool\": np.int32,\n",
    "            \"text\" : str,\n",
    "           }\n",
    "\n",
    "# json dataset path\n",
    "path = './data/yelp_academic_dataset_review.json'\n",
    "\n",
    "# chunk size used in the read_json method\n",
    "chunkSize = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe4db53",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# making a JsonReader object\n",
    "review = pd.read_json(path, lines=True,\n",
    "                      orient=\"records\",\n",
    "                      dtype=rtypes,\n",
    "                      chunksize=chunkSize)\n",
    "chunkList = []\n",
    "\n",
    "# using the chunk segmentation to manipulate only chunk data for each block\n",
    "for chunkReview in review:\n",
    "    # removing relational attributes\n",
    "    chunkReview = chunkReview.drop(['review_id', 'user_id','business_id'], axis=1)\n",
    "    chunkList.append(chunkReview)\n",
    "    \n",
    "# chunks concatenation to make the pandas dataframe \n",
    "df = pd.concat(chunkList, ignore_index=True, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe3e369",
   "metadata": {},
   "source": [
    "Keeping the idea of the chunks divisions, data loading has been reduced until reaching 1 minute and 42 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1102210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe head showing\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f84b1f5",
   "metadata": {},
   "source": [
    "The final dataframe is full of hypothetical unused information for the goals of the project. However the choice of analyzing the total properties to find possible correlations with the main fields and, if there are any, let us to be able to exploit them for the models making."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6835a436",
   "metadata": {},
   "source": [
    "## 2. Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca906c7e",
   "metadata": {},
   "source": [
    "The data analysis depicts one of the procedures that has the purpose of having to detect hidden properties on the data in order to fully understand their quality and how to make the most of it to train the models. Next, we will scan the data types of the dataframe going to analyze field by field and find possible useful information to define: data distribution, data types, correlations or dependencies between features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791a1d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# informazioni sulle colonne del dataframe e su quante entries o righe si hanno\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905d3170",
   "metadata": {},
   "source": [
    "### 2.1 Stars Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bf39f8",
   "metadata": {},
   "source": [
    "The \"star\" feature represents one of the most important data types in the entire dataset. Represents a numerical evaluation associated with the text of a reviews which, according to the official Yelp documentation, has an integer domain from 1 to 5. Since our purpose is to define a binary classification, we will aggregate the classes in order to distinguish if the reviews evaluations are positive or negative. However, we need to analyze before its structure and understand how the values are distributed in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb555473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define figure size\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "# counting stars by values and put the result in the pie plot\n",
    "df['stars'].value_counts().plot.pie(startangle=60)\n",
    "\n",
    "# define the plot title\n",
    "plt.title('Distribuzione dei valori per l\\'attributo stars')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c08912e",
   "metadata": {},
   "source": [
    "As can be seen from the previous graph, the classes are not balanced. The maximum rating of \"stars\" currently makes it impossible to divide the dataset into two opposite categories, for this reason, we are going to rebalance the values by taking a subset of reviews and dividing them between training, validation and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dd9c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of polarized or binary class stars \n",
    "binstars = pd.DataFrame()\n",
    "binstars['stars'] = [0 if star <= 3.0 else 1 for star in df['stars']]\n",
    "\n",
    "\n",
    "# define the size of the figure\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "\n",
    "# couting stars by value and put results in the pie plot\n",
    "binstars['stars'].value_counts().plot.pie(startangle=60)\n",
    "\n",
    "# define a title for the plot\n",
    "plt.title('Distribuzione dei valori positivi e negativi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0600adc2",
   "metadata": {},
   "source": [
    "Following a binary division in which the evaluations with a value greater than 3 are classified as \"positive\" while the remaining ones as \"negative\", does not make the dataset balanced. As you can see from the graph, 1 (positive) reviews have a higher quantity than reviews with 0 (negative) rating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7315455f",
   "metadata": {},
   "source": [
    "### 2.2 Cool, Fun and Useful Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d714e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert a new feature to define the text lenght \n",
    "df['textLength']  = df['text'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63264560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define correlations \n",
    "corr = df.corr()\n",
    "\n",
    "# generate heatmap with correlation results\n",
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008f57a4",
   "metadata": {},
   "source": [
    "We tried to find possible correlations between the stars and text properties and other dataset features. Following the results provided by the heatmap, we have no such correlations; therefore the secondary features were not considered useful in achieving the objectives of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084367cf",
   "metadata": {},
   "source": [
    "### 2.3 Text Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211af97c",
   "metadata": {},
   "source": [
    "The analysis of the texts was fundamental to understand what are the terms used in the reviews vocabulary and how they could be uniquely classified as one of the two categories. The aim of this section is define which are the most used terms, if we need to remove some misleading terms and which are the most used words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab1bd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# define a subset of the input dataset \n",
    "subset = df[:100000]\n",
    "# concatenation of texts in a single string and put every character in lowercase\n",
    "inputText = ' '.join(subset['text']).lower()\n",
    "\n",
    "# creation of worldcloud ignoring the stopwords\n",
    "wordCloud = WordCloud(background_color='white', stopwords=gensim.parsing.preprocessing.STOPWORDS).generate(inputText)\n",
    "# views setting using a bilinear interpolation\n",
    "plt.imshow(wordCloud, interpolation='bilinear')\n",
    "\n",
    "# set axis invisible\n",
    "plt.axis('off')\n",
    "# showing of the most frequent terms in a worldcloud plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199ba73b",
   "metadata": {},
   "source": [
    "Given the dataset's imbalance towards positive reviews, it was natural to expect that positive terms would have a higher frequency than negative ones. Specifically, from the previous worldlcloud, it is possible to see terms such as \"good\", \"delicious\" are used more frequently to describe characteristics of the service to be reviewed. From words like \"food\", \"service\", \"place\" or \"restaurant\", we can deduce how most of the reviews are related to restaurant or culinary activities. From this, therefore, we can already guess what the vocabulary may be used but, for greater precision, we have decided to be able to display the data graphically, so as to be able to have a more precise view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceabfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculae the frequent terms \n",
    "wordTokens = word_tokenize(inputText)\n",
    "tokens = list()\n",
    "for word in wordTokens:\n",
    "    if word.isalpha() and word not in gensim.parsing.preprocessing.STOPWORDS:\n",
    "        tokens.append(word)\n",
    "tokenDist = FreqDist(tokens)\n",
    "# select the 20 most frequent terms from the token dictionary\n",
    "dist = pd.DataFrame(tokenDist.most_common(20),columns=['term', 'freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b4f358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing results in a bar plot\n",
    "fig = plt.figure(figsize=(14,8))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "x = dist['term']\n",
    "y = dist['freq']\n",
    "ax.bar(x,y)\n",
    "plt.title('Frequenza dei termini piÃ¹ utilizzati')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edef1df",
   "metadata": {},
   "source": [
    "The analysis of the terms used in the texts of the reviews, points out how stopwords without a conceptual meaning are not present among the most frequent words. However, we should eliminate them anyway to reduce the variance of terms used within the dataset, this is because if the amount of words used is less, it is possible to obtain a trained and high performed classifier faster based the training phase only on most relevant conceptual wolds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb126a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51cee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference of the length between reviews from the different stars values\n",
    "graph = sns.FacetGrid(data=df,col='stars')\n",
    "graph.map(plt.hist,'textLength',bins=50,color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deb931b",
   "metadata": {},
   "source": [
    "Normalizing text length values, it can be seen that the distribution of this texts property is  similar between reviews indipendently from the stars value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc785fb3",
   "metadata": {},
   "source": [
    "## 3. Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2df9d4e",
   "metadata": {},
   "source": [
    "Data pre-processing considers some analyzed aspects discovered in data analysis and prepare the dataset for the training phase. In according to well known information, we are able to remove useless features like cool, funny, useful and textLength because they aren't correlations with stars and text field. In addition, we can modify texts as a lemmatized sequences of worlds in lowercase and without stopwords (except for negative ones which are important to determinate the result class of a review)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b587a0",
   "metadata": {},
   "source": [
    "### 3.1 Remove of unused and null data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971f53e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing of useless features\n",
    "df = df.drop(['cool', 'funny', 'useful', 'textLength'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f634de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a24dbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing of rows with null values \n",
    "df['text'].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dd3d5f",
   "metadata": {},
   "source": [
    "### 3.2 Lowercase reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05563d10",
   "metadata": {},
   "source": [
    "This kind of change is necessary to avoid different classification on a same word in lower and upper variation like \"Hello\" and \"hello\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0549018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduction of dataset text in lowecase\n",
    "df['text'] = [review_text.lower() for review_text in df['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593189b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b54a60",
   "metadata": {},
   "source": [
    "### 3.3 Stars polarization and dataset balance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f09dcc",
   "metadata": {},
   "source": [
    "To lighten the workload associated with the transformation of the dataset, we have anticipated the stars polarization. If we do it before, we should be able to manage data faster on a balanced subset that needs to be made by an equal number of positive and negative reviews in according to the polarized stars values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a393a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polarization procedure \n",
    "\n",
    "texts =  df['text']\n",
    "\n",
    "# setting stars as 1 if more than 3, otherwise set it to 0\n",
    "stars = [0 if star <= 3.0 else 1 for star in df['stars']]\n",
    "\n",
    "balancedTexts = [] # it's the balanced subset of text features\n",
    "balancedLabels = [] # it's the balanced subset of stars refered to the balanced text \n",
    "\n",
    "# limit is 200.000, so we select 400.000 reviews, 50% positive and 50% negative \n",
    "limit = 200000  \n",
    "\n",
    "# counting for negative and positive reviews added to the balanced subset\n",
    "negPosCounts = [0, 0] \n",
    "\n",
    "for i in range(0,len(texts)):\n",
    "    polarity = stars[i]\n",
    "    if negPosCounts[polarity] < limit: # if limited is not reached\n",
    "        balancedTexts.append(texts[i])\n",
    "        balancedLabels.append(stars[i])\n",
    "        negPosCounts[polarity] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd735018",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = pd.DataFrame()\n",
    "df_balanced['text'] = balancedTexts\n",
    "df_balanced['labels'] = balancedLabels\n",
    "df_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11e8cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify the balance between the two classes\n",
    "counter = Counter(df_balanced['labels'])\n",
    "print(f'Ci sono {counter[1]} recensioni positive e {counter[0]} recensioni negative')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706874dc",
   "metadata": {},
   "source": [
    "As a result of the balance, we have a dataset of 400,000 reviews in which 50% are positive and the rest negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1390066f",
   "metadata": {},
   "source": [
    "### 3.3 Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eebeb5",
   "metadata": {},
   "source": [
    "The lemmatization involves an onerous procedure on the balanced dataset. Particularly, we will associate a semantic tag to each word in order to differentiate which type of term is being analyzed and, according to the semantic class to which it belongs, carry out an ad-hoc lemmatization in order to obtain the correct normalized form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13106c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# lemmatizer making\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# word_tagger is the function to return the semantic tag associated to the given input\n",
    "def word_tagger(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:         \n",
    "        return None\n",
    "\n",
    "\n",
    "#\n",
    "texts = df_balanced['text']\n",
    "\n",
    "# lemmatize_reviews return the lemmatized text collection from the given input one.\n",
    "def lemmatize_reviews(texts):\n",
    "    df_texts = []\n",
    "    for text in texts:\n",
    "        # association between a token and the relative tag\n",
    "        word_tagged = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "        # mapping word : tag\n",
    "        map_word_tag = list(map(lambda x: (x[0], word_tagger(x[1])), word_tagged))\n",
    "        # building the lemmatized text for each text\n",
    "        lemmatized_text = []\n",
    "        for word, tag in map_word_tag:\n",
    "            if tag is None:\n",
    "                # element with no tag\n",
    "                lemmatized_text.append(word)\n",
    "            else:\n",
    "                # element with tag\n",
    "                lemmatized_text.append(lemmatizer.lemmatize(word, tag))\n",
    "        # adding the lemmatized text to the texts collection\n",
    "        lemmatized_text = \" \".join(lemmatized_text)\n",
    "        df_texts.append(lemmatized_text)\n",
    "    return df_texts\n",
    "\n",
    "df_texts = lemmatize_reviews(texts)\n",
    "print(texts[0] + \"\\n\\n\")\n",
    "print(df_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19e9428",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced['text'] = df_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c9a2b4",
   "metadata": {},
   "source": [
    "### 3.4 Removing not alfanumeric charactes and stopwords terms "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b428aa",
   "metadata": {},
   "source": [
    "As a set of stopwords, it was not possible to use the set offered by nltk as there were negative terms which, for the objectives of the project, are very important in order to distinguish the belonging of a review class. To solve this problem, we used an alternative set provided by the gensim library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c06e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords to remove\n",
    "print(gensim.parsing.preprocessing.STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d93279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing stopwords\n",
    "df_texts = []\n",
    "for text in df_balanced['text']:\n",
    "    df_texts.append(remove_stopwords(text))\n",
    "\n",
    "df_balanced['text'] = df_texts\n",
    "\n",
    "# removing not alfanumeric characters\n",
    "df_texts = []\n",
    "for text in df_balanced['text']:\n",
    "    df_texts.append(''.join(ch for ch in text if ch.isalnum() or ch == ' '))\n",
    "\n",
    "df_balanced['text'] = df_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad80eab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_balanced['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89c9c97",
   "metadata": {},
   "source": [
    "### 3.5 Text Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c3011f",
   "metadata": {},
   "source": [
    "The tokenization of texts simply involves the transformation of a text into a list of words in order to have an index of each term using matrix structure references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381069a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# tokenization using nltk world_tokenize\n",
    "df_balanced['text'] = [nltk.word_tokenize(text) for text in df_balanced['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b5bfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff653e0",
   "metadata": {},
   "source": [
    "### 3.6 Word Reviews Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf9462a",
   "metadata": {},
   "source": [
    "Since predictive models and classifiers work on numerical values, we need to transform our literal tokens into numerical values. These values will represent an identification in the real numbers field for the terms. Words that were initially placed in various forms, thanks to lemmatization, will be classified under a single numerical identifier, thus not only will reduce the amount of integer values present within each review, but will also have greater precision on semantic text perception and, consequently, improve the performance of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb23c27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verification of the number of term inside the lemmatized and balanced dataset vocabulary\n",
    "map_terms = dict()\n",
    "for text in df_balanced['text']:\n",
    "    for word in text:\n",
    "        if word not in map_terms:\n",
    "            map_terms[word] = 1\n",
    "\n",
    "print(f'There are {len(map_terms)} different words') # number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6637a1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# defining a tokenizer with the 15.000 most frequented word there is a truncation, for the short one a filling using\n",
    "# sequence of zeros\n",
    "tokenizer = Tokenizer(num_words=15000)\n",
    "tokenizer.fit_on_texts(df_balanced['text'])\n",
    "# trasformation of text in sequences\n",
    "sequences = tokenizer.texts_to_sequences(df_balanced['text'])\n",
    "# sequences are reducted by 300 words for review. For long one, there is. \n",
    "text_sequence = pad_sequences(sequences, maxlen=300)\n",
    "labels = np.array(df_balanced['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66db667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partial checking \n",
    "word_index = tokenizer.word_index\n",
    "# print the first 50 terms\n",
    "check = {key: value for key, value in word_index.items() if value <= 50}\n",
    "print(check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d896f003",
   "metadata": {},
   "source": [
    "The vector of numerical values has a domain equal to 15,000 different word types among the 132,062 total. We will therefore select more than 1/10 of the words present in the reviews which, however, have a greater relevance than 9/10 in according to their occurrences. Furthermore, the ordered sequence created will follow the order of occurrence of the terms within the texts of 300 words (maximum size)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0285bbcc",
   "metadata": {},
   "source": [
    "## 4. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7de35bd",
   "metadata": {},
   "source": [
    "At this stage it is possible to find alternative models used today for Sentiment Analysis and generally in the Natural Language Processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbcc790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking sulle compile flags di tensorflow\n",
    "print(tf.sysconfig.get_compile_flags())\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e59721",
   "metadata": {},
   "source": [
    "One of the elements that we will take as a parameter is F / F1-Score which measures the accuracy of a model on a particular set of data (testing and validation set in our case) based on the precision and recall parameters. To calculate it, simply divide the double product of the precision for recall by their sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c41c099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks management\n",
    "# class to calculate the f1 score\n",
    "class f1_score_callback(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, train, validation=None):\n",
    "        super(f1_score_callback, self).__init__()\n",
    "        self.validation = validation\n",
    "        self.train = train\n",
    "\n",
    "    # load the f1 score at the end of the epoch inherits from the callback class\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "\n",
    "        logs['f1_score_train'] = float('-inf')\n",
    "        X_train, y_train = self.train[0], self.train[1]\n",
    "        y_pred = (self.model.predict(X_train).ravel()>0.5)+0\n",
    "        score = f1_score(y_train, y_pred)  \n",
    "\n",
    "        if (self.validation):\n",
    "            logs['f1_score_val'] = float('-inf')\n",
    "            X_valid, y_valid = self.validation[0], self.validation[1]\n",
    "            y_val_pred = (self.model.predict(X_valid).ravel()>0.5) + 0\n",
    "            val_score = f1_score(y_valid, y_val_pred)\n",
    "            logs['f1_score_train'] = np.round(score, 5)\n",
    "            logs['f1_score_val'] = np.round(val_score, 5)\n",
    "        else:\n",
    "            logs['f1_score_train'] = np.round(score, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c0ff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping callbacks\n",
    "es_acc_callback = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3, verbose=0)\n",
    "es_loss_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4176dd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test splitting\n",
    "x_train, x_test, y_train, y_test = train_test_split(text_sequence , labels ,random_state=520, test_size=0.33, shuffle=True)\n",
    "\n",
    "# train and validation splitting\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train, y_train, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1981654f",
   "metadata": {},
   "source": [
    "### 4.1 LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b738482",
   "metadata": {},
   "source": [
    "The proposed model add to an input embedding layer an LSTM ones, flatten the output and gives in input to two Dense layers before the output one which use sigmoid approximation to determinate the final class of a review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2650a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making to the sequential network\n",
    "lstm = keras.Sequential([\n",
    "    layers.Embedding(15000,128,input_length=300), # word embedding\n",
    "    layers.LSTM(128,return_sequences = True,  dropout=0.2), # long-short-term-memory layer with return sequences for sequential correlation\n",
    "    layers.Flatten(), # flattering the output vector\n",
    "    layers.Dense(256, activation=\"relu\"), # hidden states\n",
    "    layers.Dense(128, activation=\"relu\"), # hidden states\n",
    "    layers.Dense(1, activation=\"sigmoid\") # output layer\n",
    "]); \n",
    "\n",
    "lstm.compile(\n",
    "    loss='binary_crossentropy', # loss function\n",
    "    optimizer='adam', # adam optimizer\n",
    "    metrics=['accuracy']) # accuracy metrics\n",
    "\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb406e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_lstm = lstm.fit(x_train, y_train, epochs=3, \n",
    "                              validation_data=(x_val, y_val), \n",
    "                              callbacks=[f1_score_callback(train=(x_train,y_train),validation=(x_val,y_val)), \n",
    "                                         es_acc_callback, es_loss_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2791e52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024fdafd",
   "metadata": {},
   "source": [
    "modelLSTM.evaluate(xTest, yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495a67ee",
   "metadata": {},
   "source": [
    "### 4.2 Convulational Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8039fe42",
   "metadata": {},
   "source": [
    "As the image recognition approach, we can consider words as pixels. Using an embedding input layer which determinate the input vector of the convulational neural network, using convulational and pooling layers, we can manage the logic feature extraction, flatten the output, gives in input to Dense layers and, finally, determinate the class using the single neuron with sigmoid activation approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1891b39d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cnn = keras.Sequential([\n",
    "    layers.Embedding(15000,128,input_length=300), # word embedding\n",
    "    layers.Conv1D(128, 8, activation=\"relu\"), # convulational layer for features pattens matching\n",
    "    layers.MaxPooling1D(pool_size=4), # max pooling to unify pattern matching\n",
    "    layers.Flatten(), # flattening the dimension of the output\n",
    "    layers.Dropout(0.2), # dropout layer\n",
    "    layers.Dense(256, activation=\"relu\"), # hidden states\n",
    "    layers.Dropout(0.2), # dropout layer\n",
    "    layers.Dense(128, activation=\"relu\"), # hidden states\n",
    "    layers.Dense(1, activation=\"sigmoid\") # output layers\n",
    "])\n",
    "\n",
    "\n",
    "cnn.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c044609",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_cnn = cnn.fit(x_train, y_train, epochs=3, \n",
    "                               validation_data=(x_val, y_val), \n",
    "                              callbacks=[f1_score_callback(train=(x_train,y_train),validation=(x_val,y_val)), \n",
    "                                         es_acc_callback, es_loss_callback], \n",
    "                              batch_size=67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d38370",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3892c2b6",
   "metadata": {},
   "source": [
    "### 4.1.1 Model based on the combination between a Convulational Neural Network and LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9455eb7",
   "metadata": {},
   "source": [
    "This model combines the convulational neural network features extraction with the classification of LSTM and, in addiction, usig Dense layers to determinate a well accured results. Finally, the computation results goes to the our typical output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d02543de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 300, 128)          1920000   \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 293, 128)          131200    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 73, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 73, 128)           131584    \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 9344)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 128)               1196160   \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 3,387,265\n",
      "Trainable params: 3,387,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# combination models between convulational neural network and LSTM previous models\n",
    "clstm = keras.Sequential([\n",
    "    layers.Embedding(15000,128,input_length=300), # word embedding\n",
    "    layers.Conv1D(128, 8, activation=\"relu\"), # convulational layer for features pattens matching\n",
    "    layers.MaxPooling1D(pool_size=4),  # max pooling to unify pattern matching\n",
    "    layers.LSTM(128,return_sequences = True,  dropout=0.2), # long-short-term-memory layer per l'acquisizione di informazioni\n",
    "    layers.Flatten(), # flattening output\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\") # output layer che restituisce il tipo di review\n",
    "])\n",
    "\n",
    "\n",
    "clstm.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "clstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32db6b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2000/2000 [==============================] - 434s 217ms/step - loss: 0.3242 - accuracy: 0.8570 - val_loss: 0.2927 - val_accuracy: 0.8726\n",
      "Epoch 2/3\n",
      "2000/2000 [==============================] - 470s 235ms/step - loss: 0.2467 - accuracy: 0.8966 - val_loss: 0.3079 - val_accuracy: 0.8676\n",
      "Epoch 3/3\n",
      "2000/2000 [==============================] - 481s 241ms/step - loss: 0.1742 - accuracy: 0.9294 - val_loss: 0.3570 - val_accuracy: 0.8598\n"
     ]
    }
   ],
   "source": [
    "results_clstm = clstm.fit(x_train, y_train, epochs=3, \n",
    "                              validation_data=(x_val, y_val), \n",
    "                              callbacks=[f1_score_callback(train=(x_train,y_train),validation=(x_val,y_val)), \n",
    "                                         es_acc_callback, es_loss_callback], \n",
    "                              batch_size=67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f0803f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clstm.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d53c8e7",
   "metadata": {},
   "source": [
    "### 4.3 Model based on the combination between a Convulational Neural Network and biLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c80b96e",
   "metadata": {},
   "source": [
    "These model is similar to the previous one. The difference is in the classification layers which use a biLSTM or bidirectional LSTM which finds correlations between features in according to their orders (not as LSTM which determinate the correlation in a unidirectional analysis that consider only correlation with a current feature and previous ones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7253c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm= keras.Sequential([\n",
    "    layers.Embedding(15000,128,input_length=300), # word embedding\n",
    "    layers.Conv1D(128, 2, activation=\"relu\"), # convulational layer for features patterns \n",
    "    layers.MaxPooling1D(pool_size=8), # max pooling to unify patterns\n",
    "    layers.Bidirectional(LSTM(128,return_sequences = True,  dropout=0.2)), # long-short-term-memory layer per l'acquisizione di informazioni\n",
    "    layers.Flatten(), # flattening output\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\") # output layer che restituisce il tipo di review\n",
    "])\n",
    "\n",
    "bilstm.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "bilstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feab0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_bidlstm = bilstm.fit(x_train, y_train, epochs=3, \n",
    "                              validation_data=(x_val, y_val), \n",
    "                              callbacks=[f1_score_callback(train=(x_train,y_train),validation=(x_val,y_val)), \n",
    "                                         es_acc_callback, es_loss_callback], \n",
    "                              batch_size=67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272f09fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba29c919",
   "metadata": {},
   "source": [
    "## 5. Save Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fbde99",
   "metadata": {},
   "source": [
    "Given the excessive time spent training the models, we decided to save them in special files using the Python pickle library, so that we can always keep them available for future tests. As you can see in the examples, the classifiers are not optimal but they provide a good support tool to be able to define whether a review is positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010bbab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# saving of the tokenizer\n",
    "with open(\"dump/tokenizer/keras_tokenizer.pickle\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "\n",
    "lstm.save(\"dump/model/yelp_lstm.hdf5\")\n",
    "cnn.save(\"dump/model/yelp_cnn.hdf5\")\n",
    "clstm.save(\"dump/model/yelp_clstm.hdf5\")\n",
    "bilstm.save(\"dump/model/yelp_bilstm.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b849dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for results class definition\n",
    "def predict_conv(predictions):\n",
    "    res = []\n",
    "    for pred in predictions:\n",
    "        if pred >= 0.5:\n",
    "            res.append(1)\n",
    "        else:\n",
    "            res.append(0)\n",
    "            \n",
    "    return res   \n",
    "predict_conv([0.8,0.4,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf5ca51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  loading of the tokenizer\n",
    "with open(\"dump/tokenizer/keras_tokenizer.pickle\", \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "# loading models\n",
    "lstm = load_model(\"dump/model/yelp_lstm.hdf5\")\n",
    "cnn = load_model(\"dump/model/yelp_cnn.hdf5\")\n",
    "clstm = load_model(\"dump/model/yelp_clstm.hdf5\")\n",
    "bilstm = load_model(\"dump/model/yelp_bilstm.hdf5\")\n",
    "\n",
    "# defines testing samples\n",
    "sample = df[:100].sample()\n",
    "text_sample = np.array(sample.text) # text array\n",
    "lem_sample = lemmatize_reviews(text_sample) # text lemmatization\n",
    "# using sequence of integers to give to the model\n",
    "sequences = tokenizer.texts_to_sequences(lem_sample) # texts to sequences of integer tokens\n",
    "data_examples = pad_sequences(sequences, maxlen=300) # sequence padding\n",
    "\n",
    "# doing predictions and save the results\n",
    "predictions_lstm = lstm.predict(data_examples)\n",
    "predictions_cnn = cnn.predict(data_examples)\n",
    "predictions_clstm = clstm.predict(data_examples)\n",
    "predictions_bid = bilstm.predict(data_examples)\n",
    "\n",
    "# print the random review taken in input and print it\n",
    "print(f\"Random review\\n: {sample}\")\n",
    "\n",
    "# print predictions\n",
    "print(f\"LSTM results:\\n {predict(predictions_lstm)}\\n\\n\")\n",
    "print(f\"Convulational Neural Network predictions results:\\n {predict(predictions_cnn)}\\n\\n\")\n",
    "print(f\"Convulational Neural Network concatenated with LSTM predictions results:\\n {predict(predictions_clstm)}\\n\\n\")\n",
    "print(f\"Convulational Neural Network concatenated with a biLSTM predictions results:\\n {predict(predictions_bid)}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616dafe1",
   "metadata": {},
   "source": [
    "## 6. Data Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3006af",
   "metadata": {},
   "source": [
    "In this section, we are going to propose a graphical representation of the results by representing the performance evaluation parameters taken into consideration: accuracy, loss, and f-score. The results to be differentiated by model and by training periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0881c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot to compare training accuracy values\n",
    "plt.plot(results_lstm.history['accuracy'])\n",
    "plt.plot(results_cnn.history['accuracy'])\n",
    "plt.plot(results_clstm.history['accuracy'])\n",
    "plt.plot(results_bid.history['accuracy'])\n",
    "plt.title('Models training accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['LSTM', 'CNN', 'CNN and LSTM', 'CNN and biLSTM'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# plot to compare validation accuracy values\n",
    "plt.plot(results_lstm.history['val_accuracy'])\n",
    "plt.plot(results_cnn.history['val_accuracy'])\n",
    "plt.plot(results_clstm.history['val_accuracy'])\n",
    "plt.plot(results_bid.history['val_accuracy'])\n",
    "plt.title('Models validations accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['LSTM', 'CNN', 'CNN and LSTM', 'CNN and biLSTM'], loc='best')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16303df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot to compare training loss values\n",
    "plt.plot(results_lstm.history['loss'])\n",
    "plt.plot(results_cnn.history['loss'])\n",
    "plt.plot(results_clstm.history['loss'])\n",
    "plt.plot(results_bid.history['loss'])\n",
    "plt.title('Models training loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['LSTM', 'CNN', 'CNN and LSTM', 'CNN and biLSTM'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# plot to compare vaidation loss values \n",
    "plt.plot(results_lstm.history['val_loss'])\n",
    "plt.plot(results_cnn.history['val_loss'])\n",
    "plt.plot(results_clstm.history['val_loss'])\n",
    "plt.plot(results_bid.history['val_loss'])\n",
    "plt.title('Models validations loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['LSTM', 'CNN', 'CNN and LSTM', 'CNN and biLSTM'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36081a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots for f1 scores\n",
    "\n",
    "plt.plot(results_lstm.history['f1_score_train'])\n",
    "plt.plot(results_cnn.history['f1_score_train'])\n",
    "plt.plot(results_clstm.history['f1_score_train'])\n",
    "plt.plot(results_bid.history['f1_score_train'])\n",
    "plt.title('Models training F1 scores values')\n",
    "plt.ylabel('F-Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['LSTM', 'CNN', 'CNN and LSTM', 'CNN and biLSTM'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(results_lstm.history['f1_score_val'])\n",
    "plt.plot(results_cnn.history['f1_score_val'])\n",
    "plt.plot(results_clstm.history['f1_score_val'])\n",
    "plt.plot(results_bid.history['f1_score_val'])\n",
    "plt.title('Analisi validation f-score dei modelli')\n",
    "plt.ylabel('F-Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['LSTM', 'CNN', 'CNN and LSTM', 'CNN and biLSTM'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb02d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7521c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
